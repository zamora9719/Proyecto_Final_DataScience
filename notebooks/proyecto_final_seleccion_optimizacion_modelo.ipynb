{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qwWasd828v-"
      },
      "source": [
        "---\n",
        "## 🤖 Fase 2: Selección de modelo y optimización de hiperparámetros\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F0fbVNJ9y_Rk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression,\n",
        "    Lasso,\n",
        "    Ridge,\n",
        "    ElasticNet,\n",
        "    LassoCV\n",
        ")\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.ensemble import (\n",
        "    ExtraTreesRegressor,\n",
        "    RandomForestRegressor,\n",
        "    AdaBoostRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    BaggingRegressor\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import uniform, loguniform, randint\n",
        "\n",
        "import sys\n",
        "sys.path.append('..\\src')\n",
        "from functions import (cv_modelos,\n",
        "                       optimizar_hiperparametros\n",
        "                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "PLb717k2oTAg",
        "outputId": "5973a898-7d58-4a2f-87f8-74eef5454740"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>deseada</th>\n",
              "      <th>x1_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>2.215558</td>\n",
              "      <td>176.46</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1058.6</td>\n",
              "      <td>780.09</td>\n",
              "      <td>28.0</td>\n",
              "      <td>-1.867265</td>\n",
              "      <td>0.900023</td>\n",
              "      <td>21.539230</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98.06</td>\n",
              "      <td>1.406881</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.65</td>\n",
              "      <td>1066.0</td>\n",
              "      <td>785.52</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.633919</td>\n",
              "      <td>0.862797</td>\n",
              "      <td>17.836744</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>192.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>931.2</td>\n",
              "      <td>842.60</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.203045</td>\n",
              "      <td>0.461557</td>\n",
              "      <td>23.404952</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.00</td>\n",
              "      <td>2.093422</td>\n",
              "      <td>210.00</td>\n",
              "      <td>3.93</td>\n",
              "      <td>882.0</td>\n",
              "      <td>699.00</td>\n",
              "      <td>28.0</td>\n",
              "      <td>-1.382800</td>\n",
              "      <td>0.338268</td>\n",
              "      <td>55.551081</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>124.10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>185.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1083.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28.0</td>\n",
              "      <td>-0.510016</td>\n",
              "      <td>0.603488</td>\n",
              "      <td>17.596806</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       x2        x3      x4    x5      x6      x7    x8        x9       x10  \\\n",
              "0    0.00  2.215558  176.46  4.49  1058.6  780.09  28.0 -1.867265  0.900023   \n",
              "1   98.06  1.406881     NaN  6.65  1066.0  785.52   NaN  0.633919  0.862797   \n",
              "2    0.00  0.000000  192.00   NaN   931.2  842.60   7.0 -0.203045  0.461557   \n",
              "3   26.00  2.093422  210.00  3.93   882.0  699.00  28.0 -1.382800  0.338268   \n",
              "4  124.10  0.000000  185.70  0.00  1083.4     NaN  28.0 -0.510016  0.603488   \n",
              "\n",
              "     deseada  x1_bin  \n",
              "0  21.539230     0.0  \n",
              "1  17.836744     1.0  \n",
              "2  23.404952     2.0  \n",
              "3  55.551081     3.0  \n",
              "4  17.596806     0.0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos = pd.read_csv('../data/df_pipeline.csv', index_col=\"Unnamed: 0\")\n",
        "datos.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyvAHikcQe6-"
      },
      "source": [
        "---\n",
        "Con la información proporcionada por el EDA, el paso siguiente es pretratar los datos antes de utilzarlos como input en los modelos.\n",
        "\n",
        "Para ello, vamos a generar 1 único pipeline de preprocesado, ya que, tras testear diversas combinaciones, se descartó la presencia de variables categóricas u ordinales camufladas entre las numéricas del dataset.\n",
        "\n",
        "En lo que respecta a las relaciones polinómicas detectadas mediante test de Ramsey, se ha desestimado su modelización debido a los problemas que arrojaban los modelos (r2 ajustado disparado incluso por encima de la unidad, error inflado, etc.).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6OQQNCtxQdgy"
      },
      "outputs": [],
      "source": [
        "y = datos['deseada']\n",
        "X = datos.drop(columns=['deseada'])\n",
        "\n",
        "prep = Pipeline([\n",
        "    ('imputadorKNN', KNNImputer(n_neighbors=7)),\n",
        "    ('escalador', RobustScaler())\n",
        "    # adoptamos escalado robusto en lugar de otras técnicas, como\n",
        "    # windsorización, para conservar toda la información posible\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# debido a la escasez de datos de entrenamiento + riesgo de overfitting\n",
        "# introducimos regularización con L1, porque sabemos que hay variables\n",
        "# que contienen muy poca información\n",
        "seed = 42\n",
        "selector_lasso = SelectFromModel(\n",
        "    LassoCV(\n",
        "        alphas=np.logspace(-4, 1, 100),\n",
        "        cv=5,\n",
        "        random_state=seed,\n",
        "        max_iter=10000\n",
        "        ),\n",
        "        threshold='median'\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LIolnrO6ejbs"
      },
      "outputs": [],
      "source": [
        "linear_models = {'OLS': LinearRegression(n_jobs=-1),\n",
        "                 'Lasso': Lasso(random_state=seed),\n",
        "                 'Ridge': Ridge(random_state=seed),\n",
        "                 'ElasticNet': ElasticNet(random_state=seed)}\n",
        "other_models = {'SVM': LinearSVR(random_state=seed),\n",
        "                'Arbol_decision': DecisionTreeRegressor(random_state=seed),\n",
        "                'Arboles_aleatorios': ExtraTreesRegressor(random_state=seed),\n",
        "                'Random_Forest': RandomForestRegressor(random_state=seed),\n",
        "                'Bagging': BaggingRegressor(random_state=seed),\n",
        "                'AdaBoost': AdaBoostRegressor(random_state=seed),\n",
        "                'GradientBoosting': GradientBoostingRegressor(random_state=seed),\n",
        "                'XGBoost': XGBRegressor(random_state=seed),\n",
        "                'KVecinos': KNeighborsRegressor(),\n",
        "                'LightGBM': LGBMRegressor(random_state=seed),\n",
        "                'CatBoost': CatBoostRegressor(random_state=seed, \n",
        "                                              verbose=False,\n",
        "                                              allow_writing_files=False)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y7NM3ia2QOnD"
      },
      "outputs": [],
      "source": [
        "# Probamos con todos los modelos instanciados\n",
        "resultados_lineales = cv_modelos(linear_models, prep, selector_lasso, X, y)\n",
        "resultados_otros = cv_modelos(other_models, prep, selector_lasso, X, y)\n",
        "resultados = {**resultados_lineales, **resultados_otros}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "16lflZB0inMn",
        "outputId": "1eb34d33-7c2c-4f0f-bc7a-be3e20ef62ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r2_test</th>\n",
              "      <th>rmse_test</th>\n",
              "      <th>mae_test</th>\n",
              "      <th>r2_test_var</th>\n",
              "      <th>rmse_test_var</th>\n",
              "      <th>mae_test_var</th>\n",
              "      <th>r2_train</th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>mae_train</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>r2_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>0.783519</td>\n",
              "      <td>7.756320</td>\n",
              "      <td>5.494502</td>\n",
              "      <td>0.000605</td>\n",
              "      <td>0.243856</td>\n",
              "      <td>0.081156</td>\n",
              "      <td>0.951252</td>\n",
              "      <td>3.700772</td>\n",
              "      <td>2.653711</td>\n",
              "      <td>2.736003</td>\n",
              "      <td>1.214077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.767889</td>\n",
              "      <td>8.004882</td>\n",
              "      <td>5.758912</td>\n",
              "      <td>0.001078</td>\n",
              "      <td>0.032925</td>\n",
              "      <td>0.031690</td>\n",
              "      <td>0.925092</td>\n",
              "      <td>4.591111</td>\n",
              "      <td>3.233669</td>\n",
              "      <td>3.799426</td>\n",
              "      <td>1.204720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoosting</th>\n",
              "      <td>0.763023</td>\n",
              "      <td>8.104149</td>\n",
              "      <td>6.072102</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>0.399260</td>\n",
              "      <td>0.154795</td>\n",
              "      <td>0.870008</td>\n",
              "      <td>6.047196</td>\n",
              "      <td>4.468032</td>\n",
              "      <td>0.198180</td>\n",
              "      <td>1.140212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.743631</td>\n",
              "      <td>8.444029</td>\n",
              "      <td>6.074711</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.147571</td>\n",
              "      <td>0.031471</td>\n",
              "      <td>0.987731</td>\n",
              "      <td>1.827648</td>\n",
              "      <td>0.732325</td>\n",
              "      <td>0.210401</td>\n",
              "      <td>1.328253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random_Forest</th>\n",
              "      <td>0.739775</td>\n",
              "      <td>8.497200</td>\n",
              "      <td>6.181261</td>\n",
              "      <td>0.000975</td>\n",
              "      <td>0.219254</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>0.953471</td>\n",
              "      <td>3.616399</td>\n",
              "      <td>2.479676</td>\n",
              "      <td>0.363971</td>\n",
              "      <td>1.288866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arboles_aleatorios</th>\n",
              "      <td>0.729654</td>\n",
              "      <td>8.670533</td>\n",
              "      <td>6.133896</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.575919</td>\n",
              "      <td>0.210503</td>\n",
              "      <td>0.989407</td>\n",
              "      <td>1.692590</td>\n",
              "      <td>0.310229</td>\n",
              "      <td>0.296799</td>\n",
              "      <td>1.355996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>0.713461</td>\n",
              "      <td>8.902772</td>\n",
              "      <td>6.435706</td>\n",
              "      <td>0.001681</td>\n",
              "      <td>0.270763</td>\n",
              "      <td>0.087474</td>\n",
              "      <td>0.941442</td>\n",
              "      <td>4.056847</td>\n",
              "      <td>2.652729</td>\n",
              "      <td>0.136271</td>\n",
              "      <td>1.319541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KVecinos</th>\n",
              "      <td>0.645013</td>\n",
              "      <td>9.928786</td>\n",
              "      <td>7.428860</td>\n",
              "      <td>0.002199</td>\n",
              "      <td>0.553593</td>\n",
              "      <td>0.227522</td>\n",
              "      <td>0.771498</td>\n",
              "      <td>8.009611</td>\n",
              "      <td>6.002164</td>\n",
              "      <td>0.094041</td>\n",
              "      <td>1.196097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>0.640330</td>\n",
              "      <td>9.994251</td>\n",
              "      <td>7.984168</td>\n",
              "      <td>0.001832</td>\n",
              "      <td>0.403600</td>\n",
              "      <td>0.153092</td>\n",
              "      <td>0.696247</td>\n",
              "      <td>9.242639</td>\n",
              "      <td>7.633498</td>\n",
              "      <td>0.185783</td>\n",
              "      <td>1.087326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arbol_decision</th>\n",
              "      <td>0.551082</td>\n",
              "      <td>11.184562</td>\n",
              "      <td>7.894710</td>\n",
              "      <td>0.002592</td>\n",
              "      <td>0.721677</td>\n",
              "      <td>0.114850</td>\n",
              "      <td>0.989407</td>\n",
              "      <td>1.692590</td>\n",
              "      <td>0.310199</td>\n",
              "      <td>0.112903</td>\n",
              "      <td>1.795391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>0.476897</td>\n",
              "      <td>12.086928</td>\n",
              "      <td>9.620006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>1.082113</td>\n",
              "      <td>0.700386</td>\n",
              "      <td>0.501242</td>\n",
              "      <td>11.843048</td>\n",
              "      <td>9.443266</td>\n",
              "      <td>0.116563</td>\n",
              "      <td>1.051049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OLS</th>\n",
              "      <td>0.476764</td>\n",
              "      <td>12.088378</td>\n",
              "      <td>9.619955</td>\n",
              "      <td>0.003034</td>\n",
              "      <td>1.088529</td>\n",
              "      <td>0.703266</td>\n",
              "      <td>0.501246</td>\n",
              "      <td>11.842998</td>\n",
              "      <td>9.443055</td>\n",
              "      <td>0.206024</td>\n",
              "      <td>1.051351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lasso</th>\n",
              "      <td>0.451316</td>\n",
              "      <td>12.389553</td>\n",
              "      <td>9.946881</td>\n",
              "      <td>0.001267</td>\n",
              "      <td>0.862363</td>\n",
              "      <td>0.620276</td>\n",
              "      <td>0.470199</td>\n",
              "      <td>12.205832</td>\n",
              "      <td>9.779700</td>\n",
              "      <td>0.087522</td>\n",
              "      <td>1.041838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.437835</td>\n",
              "      <td>12.494326</td>\n",
              "      <td>9.568882</td>\n",
              "      <td>0.006842</td>\n",
              "      <td>1.053229</td>\n",
              "      <td>0.466248</td>\n",
              "      <td>0.464549</td>\n",
              "      <td>12.270129</td>\n",
              "      <td>9.312260</td>\n",
              "      <td>0.089754</td>\n",
              "      <td>1.061014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNet</th>\n",
              "      <td>0.373313</td>\n",
              "      <td>13.247646</td>\n",
              "      <td>10.670406</td>\n",
              "      <td>0.000563</td>\n",
              "      <td>0.916742</td>\n",
              "      <td>0.655854</td>\n",
              "      <td>0.383523</td>\n",
              "      <td>13.165301</td>\n",
              "      <td>10.575400</td>\n",
              "      <td>0.085442</td>\n",
              "      <td>1.027347</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     r2_test  rmse_test   mae_test  r2_test_var  \\\n",
              "CatBoost            0.783519   7.756320   5.494502     0.000605   \n",
              "LightGBM            0.767889   8.004882   5.758912     0.001078   \n",
              "GradientBoosting    0.763023   8.104149   6.072102     0.001212   \n",
              "XGBoost             0.743631   8.444029   6.074711     0.000609   \n",
              "Random_Forest       0.739775   8.497200   6.181261     0.000975   \n",
              "Arboles_aleatorios  0.729654   8.670533   6.133896     0.001300   \n",
              "Bagging             0.713461   8.902772   6.435706     0.001681   \n",
              "KVecinos            0.645013   9.928786   7.428860     0.002199   \n",
              "AdaBoost            0.640330   9.994251   7.984168     0.001832   \n",
              "Arbol_decision      0.551082  11.184562   7.894710     0.002592   \n",
              "Ridge               0.476897  12.086928   9.620006     0.003003   \n",
              "OLS                 0.476764  12.088378   9.619955     0.003034   \n",
              "Lasso               0.451316  12.389553   9.946881     0.001267   \n",
              "SVM                 0.437835  12.494326   9.568882     0.006842   \n",
              "ElasticNet          0.373313  13.247646  10.670406     0.000563   \n",
              "\n",
              "                    rmse_test_var  mae_test_var  r2_train  rmse_train  \\\n",
              "CatBoost                 0.243856      0.081156  0.951252    3.700772   \n",
              "LightGBM                 0.032925      0.031690  0.925092    4.591111   \n",
              "GradientBoosting         0.399260      0.154795  0.870008    6.047196   \n",
              "XGBoost                  0.147571      0.031471  0.987731    1.827648   \n",
              "Random_Forest            0.219254      0.086061  0.953471    3.616399   \n",
              "Arboles_aleatorios       0.575919      0.210503  0.989407    1.692590   \n",
              "Bagging                  0.270763      0.087474  0.941442    4.056847   \n",
              "KVecinos                 0.553593      0.227522  0.771498    8.009611   \n",
              "AdaBoost                 0.403600      0.153092  0.696247    9.242639   \n",
              "Arbol_decision           0.721677      0.114850  0.989407    1.692590   \n",
              "Ridge                    1.082113      0.700386  0.501242   11.843048   \n",
              "OLS                      1.088529      0.703266  0.501246   11.842998   \n",
              "Lasso                    0.862363      0.620276  0.470199   12.205832   \n",
              "SVM                      1.053229      0.466248  0.464549   12.270129   \n",
              "ElasticNet               0.916742      0.655854  0.383523   13.165301   \n",
              "\n",
              "                    mae_train  fit_time  r2_ratio  \n",
              "CatBoost             2.653711  2.736003  1.214077  \n",
              "LightGBM             3.233669  3.799426  1.204720  \n",
              "GradientBoosting     4.468032  0.198180  1.140212  \n",
              "XGBoost              0.732325  0.210401  1.328253  \n",
              "Random_Forest        2.479676  0.363971  1.288866  \n",
              "Arboles_aleatorios   0.310229  0.296799  1.355996  \n",
              "Bagging              2.652729  0.136271  1.319541  \n",
              "KVecinos             6.002164  0.094041  1.196097  \n",
              "AdaBoost             7.633498  0.185783  1.087326  \n",
              "Arbol_decision       0.310199  0.112903  1.795391  \n",
              "Ridge                9.443266  0.116563  1.051049  \n",
              "OLS                  9.443055  0.206024  1.051351  \n",
              "Lasso                9.779700  0.087522  1.041838  \n",
              "SVM                  9.312260  0.089754  1.061014  \n",
              "ElasticNet          10.575400  0.085442  1.027347  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resultados = pd.DataFrame.from_dict(resultados, orient='index')\n",
        "df_resultados.sort_values(by=['r2_test'], ascending=False, inplace=True)\n",
        "df_resultados.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OIaVQ5qcc62"
      },
      "source": [
        "---\n",
        "De todos los modelos evaluados, los que arrojan mejores métricas en test son:\n",
        "\n",
        "\n",
        "1.   Category Boost\n",
        "2.   LightGBM\n",
        "3.   Gradient Boosting\n",
        "\n",
        "Las varianzas que presentan para la validación cruzada en R² son bastante aceptables, lo que indica que no hay mucha variación entre foldings.\n",
        "\n",
        "Si bien es cierto que los modelos basados en árboles han demostrado ser superiores en explicabilidad a los modelos lineales, la realidad es que los modelos que mejor rendimiento presentan también dan signos de overfitting (R² en training es superior al de test).\n",
        "\n",
        "Esto se debe, entre otros potenciales factores, al reducido conjunto de datos que tenemos disponible, y que hace que el ratio entre registros (n) y variables independientes (k) se quede muy cerca de sobrepasar el margen óptimo.\n",
        "\n",
        "Puesto que ya se ha hecho selección de variables en el pipeline, el siguiente paso es optimizar hiperparámetros de los modelos, teniendo en mente que el principal objetivo es reducir el overfitting.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "452eunFEdEOs"
      },
      "outputs": [],
      "source": [
        "gb_params = {\n",
        "    'n_estimators': randint(100, 800),\n",
        "    'learning_rate': loguniform(0.01, 0.3),\n",
        "    'max_depth': randint(3, 12),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': uniform(0.5, 0.5)\n",
        "}\n",
        "\n",
        "lgbm_params = {\n",
        "    'n_estimators': randint(100, 1000),\n",
        "    'learning_rate': loguniform(0.01, 0.3),\n",
        "    'max_depth': randint(3, 15),\n",
        "    'num_leaves': randint(20, 80),\n",
        "    'min_child_samples': randint(5, 30),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'reg_alpha': loguniform(1e-6, 10),\n",
        "    'reg_lambda': loguniform(1e-6, 10)\n",
        "}\n",
        "\n",
        "cat_params = {\n",
        "    'iterations': randint(100, 1000),\n",
        "    'learning_rate': loguniform(0.01, 0.3),\n",
        "    'depth': randint(3, 12),\n",
        "    'l2_leaf_reg': loguniform(1e-3, 10),\n",
        "    'bagging_temperature': uniform(0, 1),\n",
        "    'border_count': randint(32, 255),\n",
        "    'random_strength': uniform(0, 1),\n",
        "    'subsample': uniform(0.6, 0.4)\n",
        "}\n",
        "\n",
        "gb_params_pipeline = {f'modelo__{k}': v for k, v in gb_params.items()}\n",
        "lgbm_params_pipeline = {f'modelo__{k}': v for k, v in lgbm_params.items()}\n",
        "cat_params_pipeline = {f'modelo__{k}': v for k, v in cat_params.items()}\n",
        "\n",
        "modelos_parametros_pipeline = {\n",
        "    'GradientBoosting': (GradientBoostingRegressor(random_state=seed),\n",
        "                         gb_params_pipeline),\n",
        "    'LightGBM': (LGBMRegressor(random_state=seed), lgbm_params_pipeline),\n",
        "    'CatBoost': (CatBoostRegressor(random_state=seed, verbose=False),\n",
        "                 cat_params_pipeline)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O6umwX5B8tTp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-7 (_readerthread):\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\datasci_minimal\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\datasci_minimal\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
            "    _threading_Thread_run(self)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\datasci_minimal\\Lib\\threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\datasci_minimal\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
            "    buffer.append(fh.read())\n",
            "                  ^^^^^^^^^\n",
            "  File \"<frozen codecs>\", line 322, in decode\n",
            "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa2 in position 107: invalid start byte\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 437\n",
            "[LightGBM] [Info] Number of data points in the train set: 772, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 35.895711\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "                                                    mejor_estimador  \\\n",
            "GradientBoosting  ((KNNImputer(n_neighbors=7), RobustScaler()), ...   \n",
            "LightGBM          ((KNNImputer(n_neighbors=7), RobustScaler()), ...   \n",
            "CatBoost          ((KNNImputer(n_neighbors=7), RobustScaler()), ...   \n",
            "\n",
            "                                                 mejores_parametros  mejor_r2  \\\n",
            "GradientBoosting  {'modelo__learning_rate': 0.017279572377986996...  0.781521   \n",
            "LightGBM          {'modelo__colsample_bytree': 0.665173770832571...  0.774191   \n",
            "CatBoost          {'modelo__bagging_temperature': 0.456534570482...  0.779901   \n",
            "\n",
            "                  mejor_rmse_test  mejor_mae_test  mejor_r2_train  \\\n",
            "GradientBoosting         7.787158        5.627988        0.923192   \n",
            "LightGBM                 7.925856        5.697552        0.943263   \n",
            "CatBoost                 7.817140        5.529641        0.937426   \n",
            "\n",
            "                  mejor_rmse_train  mejor_mae_train  r2_var_test  \\\n",
            "GradientBoosting          4.649021         3.324206     0.000694   \n",
            "LightGBM                  3.994817         2.728985     0.000552   \n",
            "CatBoost                  4.194494         3.030839     0.000632   \n",
            "\n",
            "                  r2_var_train  rmse_var_test  rmse_var_train    r2_gap  \n",
            "GradientBoosting      0.000004       0.203665        0.017846  0.141671  \n",
            "LightGBM              0.000006       0.238684        0.015339  0.169072  \n",
            "CatBoost              0.000011       0.173956        0.018106  0.157525  \n"
          ]
        }
      ],
      "source": [
        "opt = optimizar_hiperparametros(modelos_parametros_pipeline, \n",
        "                                prep, selector_lasso, \n",
        "                                X, \n",
        "                                y, \n",
        "                                seed)\n",
        "df_opt = pd.DataFrame.from_dict(opt, orient='index')\n",
        "print(df_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_opt.to_excel('params_opt.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datasci_minimal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

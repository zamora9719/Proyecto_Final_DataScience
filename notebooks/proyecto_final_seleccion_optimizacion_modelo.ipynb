{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qwWasd828v-"
      },
      "source": [
        "---\n",
        "##  Fase 2: Selecci贸n de modelo y optimizaci贸n de hiperpar谩metros\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F0fbVNJ9y_Rk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import (\n",
        "    LinearRegression,\n",
        "    Lasso,\n",
        "    Ridge,\n",
        "    ElasticNet,\n",
        "    LassoCV\n",
        ")\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.ensemble import (\n",
        "    ExtraTreesRegressor,\n",
        "    RandomForestRegressor,\n",
        "    AdaBoostRegressor,\n",
        "    GradientBoostingRegressor,\n",
        "    BaggingRegressor\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import uniform, loguniform, randint\n",
        "\n",
        "import sys\n",
        "sys.path.append('..\\src')\n",
        "from functions import (cv_modelos,\n",
        "                       optimizar_hiperparametros\n",
        "                       )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "PLb717k2oTAg",
        "outputId": "5973a898-7d58-4a2f-87f8-74eef5454740"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>deseada</th>\n",
              "      <th>x1_bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>2.215558</td>\n",
              "      <td>176.46</td>\n",
              "      <td>4.49</td>\n",
              "      <td>1058.6</td>\n",
              "      <td>780.09</td>\n",
              "      <td>28.0</td>\n",
              "      <td>-1.867265</td>\n",
              "      <td>0.900023</td>\n",
              "      <td>21.539230</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98.06</td>\n",
              "      <td>1.406881</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.65</td>\n",
              "      <td>1066.0</td>\n",
              "      <td>785.52</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.633919</td>\n",
              "      <td>0.862797</td>\n",
              "      <td>17.836744</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>192.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>931.2</td>\n",
              "      <td>842.60</td>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.203045</td>\n",
              "      <td>0.461557</td>\n",
              "      <td>23.404952</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.00</td>\n",
              "      <td>2.093422</td>\n",
              "      <td>210.00</td>\n",
              "      <td>3.93</td>\n",
              "      <td>882.0</td>\n",
              "      <td>699.00</td>\n",
              "      <td>28.0</td>\n",
              "      <td>-1.382800</td>\n",
              "      <td>0.338268</td>\n",
              "      <td>55.551081</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>124.10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>185.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1083.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28.0</td>\n",
              "      <td>-0.510016</td>\n",
              "      <td>0.603488</td>\n",
              "      <td>17.596806</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       x2        x3      x4    x5      x6      x7    x8        x9       x10  \\\n",
              "0    0.00  2.215558  176.46  4.49  1058.6  780.09  28.0 -1.867265  0.900023   \n",
              "1   98.06  1.406881     NaN  6.65  1066.0  785.52   NaN  0.633919  0.862797   \n",
              "2    0.00  0.000000  192.00   NaN   931.2  842.60   7.0 -0.203045  0.461557   \n",
              "3   26.00  2.093422  210.00  3.93   882.0  699.00  28.0 -1.382800  0.338268   \n",
              "4  124.10  0.000000  185.70  0.00  1083.4     NaN  28.0 -0.510016  0.603488   \n",
              "\n",
              "     deseada  x1_bin  \n",
              "0  21.539230     0.0  \n",
              "1  17.836744     1.0  \n",
              "2  23.404952     2.0  \n",
              "3  55.551081     3.0  \n",
              "4  17.596806     0.0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos = pd.read_csv('../data/df_pipeline.csv', index_col=\"Unnamed: 0\")\n",
        "datos.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyvAHikcQe6-"
      },
      "source": [
        "---\n",
        "Con la informaci贸n proporcionada por el EDA, el paso siguiente es pretratar los datos antes de utilzarlos como input en los modelos.\n",
        "\n",
        "Para ello, vamos a generar 1 煤nico pipeline de preprocesado, ya que, tras testear diversas combinaciones, se descart贸 la presencia de variables categ贸ricas u ordinales camufladas entre las num茅ricas del dataset.\n",
        "\n",
        "En lo que respecta a las relaciones polin贸micas detectadas mediante test de Ramsey, se ha desestimado su modelizaci贸n debido a los problemas que arrojaban los modelos (r2 ajustado disparado incluso por encima de la unidad, error inflado, etc.).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6OQQNCtxQdgy"
      },
      "outputs": [],
      "source": [
        "y = datos['deseada']\n",
        "X = datos.drop(columns=['deseada'])\n",
        "\n",
        "prep = Pipeline([\n",
        "    ('imputadorKNN', KNNImputer(n_neighbors=7)),\n",
        "    ('escalador', RobustScaler())\n",
        "    # adoptamos escalado robusto en lugar de otras t茅cnicas, como\n",
        "    # windsorizaci贸n, para conservar toda la informaci贸n posible\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# debido a la escasez de datos de entrenamiento + riesgo de overfitting\n",
        "# introducimos regularizaci贸n con L1, porque sabemos que hay variables\n",
        "# que contienen muy poca informaci贸n\n",
        "seed = 42\n",
        "selector_lasso = SelectFromModel(\n",
        "    LassoCV(\n",
        "        alphas=np.logspace(-4, 1, 100),\n",
        "        cv=5,\n",
        "        random_state=seed,\n",
        "        max_iter=10000\n",
        "        ),\n",
        "        threshold='median'\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LIolnrO6ejbs"
      },
      "outputs": [],
      "source": [
        "linear_models = {'OLS': LinearRegression(n_jobs=-1),\n",
        "                 'Lasso': Lasso(random_state=seed),\n",
        "                 'Ridge': Ridge(random_state=seed),\n",
        "                 'ElasticNet': ElasticNet(random_state=seed)}\n",
        "other_models = {'SVM': LinearSVR(random_state=seed),\n",
        "                'Arbol_decision': DecisionTreeRegressor(random_state=seed),\n",
        "                'Arboles_aleatorios': ExtraTreesRegressor(random_state=seed),\n",
        "                'Random_Forest': RandomForestRegressor(random_state=seed),\n",
        "                'Bagging': BaggingRegressor(random_state=seed),\n",
        "                'AdaBoost': AdaBoostRegressor(random_state=seed),\n",
        "                'GradientBoosting': GradientBoostingRegressor(random_state=seed),\n",
        "                'XGBoost': XGBRegressor(random_state=seed),\n",
        "                'KVecinos': KNeighborsRegressor(),\n",
        "                'LightGBM': LGBMRegressor(random_state=seed),\n",
        "                'CatBoost': CatBoostRegressor(random_state=seed, \n",
        "                                              verbose=False,\n",
        "                                              allow_writing_files=False)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y7NM3ia2QOnD"
      },
      "outputs": [],
      "source": [
        "# Probamos con todos los modelos instanciados\n",
        "resultados_lineales = cv_modelos(linear_models, prep, selector_lasso, X, y)\n",
        "resultados_otros = cv_modelos(other_models, prep, selector_lasso, X, y)\n",
        "resultados = {**resultados_lineales, **resultados_otros}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "16lflZB0inMn",
        "outputId": "1eb34d33-7c2c-4f0f-bc7a-be3e20ef62ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r2_test</th>\n",
              "      <th>rmse_test</th>\n",
              "      <th>mae_test</th>\n",
              "      <th>r2_test_var</th>\n",
              "      <th>rmse_test_var</th>\n",
              "      <th>mae_test_var</th>\n",
              "      <th>r2_train</th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>mae_train</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>r2_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CatBoost</th>\n",
              "      <td>0.783519</td>\n",
              "      <td>7.756320</td>\n",
              "      <td>5.494502</td>\n",
              "      <td>0.000605</td>\n",
              "      <td>0.243856</td>\n",
              "      <td>0.081156</td>\n",
              "      <td>0.951252</td>\n",
              "      <td>3.700772</td>\n",
              "      <td>2.653711</td>\n",
              "      <td>2.736003</td>\n",
              "      <td>1.214077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.767889</td>\n",
              "      <td>8.004882</td>\n",
              "      <td>5.758912</td>\n",
              "      <td>0.001078</td>\n",
              "      <td>0.032925</td>\n",
              "      <td>0.031690</td>\n",
              "      <td>0.925092</td>\n",
              "      <td>4.591111</td>\n",
              "      <td>3.233669</td>\n",
              "      <td>3.799426</td>\n",
              "      <td>1.204720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoosting</th>\n",
              "      <td>0.763023</td>\n",
              "      <td>8.104149</td>\n",
              "      <td>6.072102</td>\n",
              "      <td>0.001212</td>\n",
              "      <td>0.399260</td>\n",
              "      <td>0.154795</td>\n",
              "      <td>0.870008</td>\n",
              "      <td>6.047196</td>\n",
              "      <td>4.468032</td>\n",
              "      <td>0.198180</td>\n",
              "      <td>1.140212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.743631</td>\n",
              "      <td>8.444029</td>\n",
              "      <td>6.074711</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.147571</td>\n",
              "      <td>0.031471</td>\n",
              "      <td>0.987731</td>\n",
              "      <td>1.827648</td>\n",
              "      <td>0.732325</td>\n",
              "      <td>0.210401</td>\n",
              "      <td>1.328253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random_Forest</th>\n",
              "      <td>0.739775</td>\n",
              "      <td>8.497200</td>\n",
              "      <td>6.181261</td>\n",
              "      <td>0.000975</td>\n",
              "      <td>0.219254</td>\n",
              "      <td>0.086061</td>\n",
              "      <td>0.953471</td>\n",
              "      <td>3.616399</td>\n",
              "      <td>2.479676</td>\n",
              "      <td>0.363971</td>\n",
              "      <td>1.288866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arboles_aleatorios</th>\n",
              "      <td>0.729654</td>\n",
              "      <td>8.670533</td>\n",
              "      <td>6.133896</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.575919</td>\n",
              "      <td>0.210503</td>\n",
              "      <td>0.989407</td>\n",
              "      <td>1.692590</td>\n",
              "      <td>0.310229</td>\n",
              "      <td>0.296799</td>\n",
              "      <td>1.355996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bagging</th>\n",
              "      <td>0.713461</td>\n",
              "      <td>8.902772</td>\n",
              "      <td>6.435706</td>\n",
              "      <td>0.001681</td>\n",
              "      <td>0.270763</td>\n",
              "      <td>0.087474</td>\n",
              "      <td>0.941442</td>\n",
              "      <td>4.056847</td>\n",
              "      <td>2.652729</td>\n",
              "      <td>0.136271</td>\n",
              "      <td>1.319541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KVecinos</th>\n",
              "      <td>0.645013</td>\n",
              "      <td>9.928786</td>\n",
              "      <td>7.428860</td>\n",
              "      <td>0.002199</td>\n",
              "      <td>0.553593</td>\n",
              "      <td>0.227522</td>\n",
              "      <td>0.771498</td>\n",
              "      <td>8.009611</td>\n",
              "      <td>6.002164</td>\n",
              "      <td>0.094041</td>\n",
              "      <td>1.196097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>0.640330</td>\n",
              "      <td>9.994251</td>\n",
              "      <td>7.984168</td>\n",
              "      <td>0.001832</td>\n",
              "      <td>0.403600</td>\n",
              "      <td>0.153092</td>\n",
              "      <td>0.696247</td>\n",
              "      <td>9.242639</td>\n",
              "      <td>7.633498</td>\n",
              "      <td>0.185783</td>\n",
              "      <td>1.087326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arbol_decision</th>\n",
              "      <td>0.551082</td>\n",
              "      <td>11.184562</td>\n",
              "      <td>7.894710</td>\n",
              "      <td>0.002592</td>\n",
              "      <td>0.721677</td>\n",
              "      <td>0.114850</td>\n",
              "      <td>0.989407</td>\n",
              "      <td>1.692590</td>\n",
              "      <td>0.310199</td>\n",
              "      <td>0.112903</td>\n",
              "      <td>1.795391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>0.476897</td>\n",
              "      <td>12.086928</td>\n",
              "      <td>9.620006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>1.082113</td>\n",
              "      <td>0.700386</td>\n",
              "      <td>0.501242</td>\n",
              "      <td>11.843048</td>\n",
              "      <td>9.443266</td>\n",
              "      <td>0.116563</td>\n",
              "      <td>1.051049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OLS</th>\n",
              "      <td>0.476764</td>\n",
              "      <td>12.088378</td>\n",
              "      <td>9.619955</td>\n",
              "      <td>0.003034</td>\n",
              "      <td>1.088529</td>\n",
              "      <td>0.703266</td>\n",
              "      <td>0.501246</td>\n",
              "      <td>11.842998</td>\n",
              "      <td>9.443055</td>\n",
              "      <td>0.206024</td>\n",
              "      <td>1.051351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lasso</th>\n",
              "      <td>0.451316</td>\n",
              "      <td>12.389553</td>\n",
              "      <td>9.946881</td>\n",
              "      <td>0.001267</td>\n",
              "      <td>0.862363</td>\n",
              "      <td>0.620276</td>\n",
              "      <td>0.470199</td>\n",
              "      <td>12.205832</td>\n",
              "      <td>9.779700</td>\n",
              "      <td>0.087522</td>\n",
              "      <td>1.041838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.437835</td>\n",
              "      <td>12.494326</td>\n",
              "      <td>9.568882</td>\n",
              "      <td>0.006842</td>\n",
              "      <td>1.053229</td>\n",
              "      <td>0.466248</td>\n",
              "      <td>0.464549</td>\n",
              "      <td>12.270129</td>\n",
              "      <td>9.312260</td>\n",
              "      <td>0.089754</td>\n",
              "      <td>1.061014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ElasticNet</th>\n",
              "      <td>0.373313</td>\n",
              "      <td>13.247646</td>\n",
              "      <td>10.670406</td>\n",
              "      <td>0.000563</td>\n",
              "      <td>0.916742</td>\n",
              "      <td>0.655854</td>\n",
              "      <td>0.383523</td>\n",
              "      <td>13.165301</td>\n",
              "      <td>10.575400</td>\n",
              "      <td>0.085442</td>\n",
              "      <td>1.027347</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     r2_test  rmse_test   mae_test  r2_test_var  \\\n",
              "CatBoost            0.783519   7.756320   5.494502     0.000605   \n",
              "LightGBM            0.767889   8.004882   5.758912     0.001078   \n",
              "GradientBoosting    0.763023   8.104149   6.072102     0.001212   \n",
              "XGBoost             0.743631   8.444029   6.074711     0.000609   \n",
              "Random_Forest       0.739775   8.497200   6.181261     0.000975   \n",
              "Arboles_aleatorios  0.729654   8.670533   6.133896     0.001300   \n",
              "Bagging             0.713461   8.902772   6.435706     0.001681   \n",
              "KVecinos            0.645013   9.928786   7.428860     0.002199   \n",
              "AdaBoost            0.640330   9.994251   7.984168     0.001832   \n",
              "Arbol_decision      0.551082  11.184562   7.894710     0.002592   \n",
              "Ridge               0.476897  12.086928   9.620006     0.003003   \n",
              "OLS                 0.476764  12.088378   9.619955     0.003034   \n",
              "Lasso               0.451316  12.389553   9.946881     0.001267   \n",
              "SVM                 0.437835  12.494326   9.568882     0.006842   \n",
              "ElasticNet          0.373313  13.247646  10.670406     0.000563   \n",
              "\n",
              "                    rmse_test_var  mae_test_var  r2_train  rmse_train  \\\n",
              "CatBoost                 0.243856      0.081156  0.951252    3.700772   \n",
              "LightGBM                 0.032925      0.031690  0.925092    4.591111   \n",
              "GradientBoosting         0.399260      0.154795  0.870008    6.047196   \n",
              "XGBoost                  0.147571      0.031471  0.987731    1.827648   \n",
              "Random_Forest            0.219254      0.086061  0.953471    3.616399   \n",
              "Arboles_aleatorios       0.575919      0.210503  0.989407    1.692590   \n",
              "Bagging                  0.270763      0.087474  0.941442    4.056847   \n",
              "KVecinos                 0.553593      0.227522  0.771498    8.009611   \n",
              "AdaBoost                 0.403600      0.153092  0.696247    9.242639   \n",
              "Arbol_decision           0.721677      0.114850  0.989407    1.692590   \n",
              "Ridge                    1.082113      0.700386  0.501242   11.843048   \n",
              "OLS                      1.088529      0.703266  0.501246   11.842998   \n",
              "Lasso                    0.862363      0.620276  0.470199   12.205832   \n",
              "SVM                      1.053229      0.466248  0.464549   12.270129   \n",
              "ElasticNet               0.916742      0.655854  0.383523   13.165301   \n",
              "\n",
              "                    mae_train  fit_time  r2_ratio  \n",
              "CatBoost             2.653711  2.736003  1.214077  \n",
              "LightGBM             3.233669  3.799426  1.204720  \n",
              "GradientBoosting     4.468032  0.198180  1.140212  \n",
              "XGBoost              0.732325  0.210401  1.328253  \n",
              "Random_Forest        2.479676  0.363971  1.288866  \n",
              "Arboles_aleatorios   0.310229  0.296799  1.355996  \n",
              "Bagging              2.652729  0.136271  1.319541  \n",
              "KVecinos             6.002164  0.094041  1.196097  \n",
              "AdaBoost             7.633498  0.185783  1.087326  \n",
              "Arbol_decision       0.310199  0.112903  1.795391  \n",
              "Ridge                9.443266  0.116563  1.051049  \n",
              "OLS                  9.443055  0.206024  1.051351  \n",
              "Lasso                9.779700  0.087522  1.041838  \n",
              "SVM                  9.312260  0.089754  1.061014  \n",
              "ElasticNet          10.575400  0.085442  1.027347  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resultados = pd.DataFrame.from_dict(resultados, orient='index')\n",
        "df_resultados.sort_values(by=['r2_test'], ascending=False, inplace=True)\n",
        "df_resultados.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OIaVQ5qcc62"
      },
      "source": [
        "---\n",
        "De todos los modelos evaluados, los que arrojan mejores m茅tricas en test son:\n",
        "\n",
        "\n",
        "1.   Category Boost\n",
        "2.   LightGBM\n",
        "3.   Gradient Boosting\n",
        "\n",
        "Las varianzas que presentan para la validaci贸n cruzada en R虏 son bastante aceptables, lo que indica que no hay mucha variaci贸n entre foldings.\n",
        "\n",
        "Si bien es cierto que los modelos basados en 谩rboles han demostrado ser superiores en explicabilidad a los modelos lineales, la realidad es que los modelos que mejor rendimiento presentan tambi茅n dan signos de overfitting (R虏 en training es superior al de test).\n",
        "\n",
        "Esto se debe, entre otros potenciales factores, al reducido conjunto de datos que tenemos disponible, y que hace que el ratio entre registros (n) y variables independientes (k) se quede muy cerca de sobrepasar el margen 贸ptimo.\n",
        "\n",
        "Puesto que ya se ha hecho selecci贸n de variables en el pipeline, el siguiente paso es optimizar hiperpar谩metros de los modelos, teniendo en mente que el principal objetivo es reducir el overfitting.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "452eunFEdEOs"
      },
      "outputs": [],
      "source": [
        "gb_params = {\n",
        "    'n_estimators': randint(100, 800),\n",
        "    'learning_rate': loguniform(0.01, 0.3),\n",
        "    'max_depth': randint(3, 12),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': uniform(0.5, 0.5)\n",
        "}\n",
        "\n",
        "lgbm_params = {\n",
        "    'n_estimators': randint(100, 1000),\n",
        "    'learning_rate': loguniform(0.01, 0.3),\n",
        "    'max_depth': randint(3, 15),\n",
        "    'num_leaves': randint(20, 80),\n",
        "    'min_child_samples': randint(5, 30),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'reg_alpha': loguniform(1e-6, 10),\n",
        "    'reg_lambda': loguniform(1e-6, 10)\n",
        "}\n",
        "\n",
        "cat_params = {\n",
        "    'iterations': randint(100, 1000),\n",
        "    'learning_rate': loguniform(0.01, 0.3),\n",
        "    'depth': randint(3, 12),\n",
        "    'l2_leaf_reg': loguniform(1e-3, 10),\n",
        "    'bagging_temperature': uniform(0, 1),\n",
        "    'border_count': randint(32, 255),\n",
        "    'random_strength': uniform(0, 1),\n",
        "    'subsample': uniform(0.6, 0.4)\n",
        "}\n",
        "\n",
        "gb_params_pipeline = {f'modelo__{k}': v for k, v in gb_params.items()}\n",
        "lgbm_params_pipeline = {f'modelo__{k}': v for k, v in lgbm_params.items()}\n",
        "cat_params_pipeline = {f'modelo__{k}': v for k, v in cat_params.items()}\n",
        "\n",
        "modelos_parametros_pipeline = {\n",
        "    'GradientBoosting': (GradientBoostingRegressor(random_state=seed),\n",
        "                         gb_params_pipeline),\n",
        "    'LightGBM': (LGBMRegressor(random_state=seed), lgbm_params_pipeline),\n",
        "    'CatBoost': (CatBoostRegressor(random_state=seed, verbose=False),\n",
        "                 cat_params_pipeline)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O6umwX5B8tTp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-7 (_readerthread):\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\datasci_minimal\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\datasci_minimal\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
            "    _threading_Thread_run(self)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\datasci_minimal\\Lib\\threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"c:\\ProgramData\\anaconda3\\envs\\datasci_minimal\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
            "    buffer.append(fh.read())\n",
            "                  ^^^^^^^^^\n",
            "  File \"<frozen codecs>\", line 322, in decode\n",
            "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa2 in position 107: invalid start byte\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 437\n",
            "[LightGBM] [Info] Number of data points in the train set: 772, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 35.895711\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "                                                    mejor_estimador  \\\n",
            "GradientBoosting  ((KNNImputer(n_neighbors=7), RobustScaler()), ...   \n",
            "LightGBM          ((KNNImputer(n_neighbors=7), RobustScaler()), ...   \n",
            "CatBoost          ((KNNImputer(n_neighbors=7), RobustScaler()), ...   \n",
            "\n",
            "                                                 mejores_parametros  mejor_r2  \\\n",
            "GradientBoosting  {'modelo__learning_rate': 0.017279572377986996...  0.781521   \n",
            "LightGBM          {'modelo__colsample_bytree': 0.665173770832571...  0.774191   \n",
            "CatBoost          {'modelo__bagging_temperature': 0.456534570482...  0.779901   \n",
            "\n",
            "                  mejor_rmse_test  mejor_mae_test  mejor_r2_train  \\\n",
            "GradientBoosting         7.787158        5.627988        0.923192   \n",
            "LightGBM                 7.925856        5.697552        0.943263   \n",
            "CatBoost                 7.817140        5.529641        0.937426   \n",
            "\n",
            "                  mejor_rmse_train  mejor_mae_train  r2_var_test  \\\n",
            "GradientBoosting          4.649021         3.324206     0.000694   \n",
            "LightGBM                  3.994817         2.728985     0.000552   \n",
            "CatBoost                  4.194494         3.030839     0.000632   \n",
            "\n",
            "                  r2_var_train  rmse_var_test  rmse_var_train    r2_gap  \n",
            "GradientBoosting      0.000004       0.203665        0.017846  0.141671  \n",
            "LightGBM              0.000006       0.238684        0.015339  0.169072  \n",
            "CatBoost              0.000011       0.173956        0.018106  0.157525  \n"
          ]
        }
      ],
      "source": [
        "opt = optimizar_hiperparametros(modelos_parametros_pipeline, \n",
        "                                prep, selector_lasso, \n",
        "                                X, \n",
        "                                y, \n",
        "                                seed)\n",
        "df_opt = pd.DataFrame.from_dict(opt, orient='index')\n",
        "print(df_opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_opt.to_excel('params_opt.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "datasci_minimal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
